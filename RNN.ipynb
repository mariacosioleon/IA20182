{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNVhb9ls6RhxBc+i7LjSfI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariacosioleon/IA20182/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bxoMPp9QaZ8X"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#se debe cargar el fichero “Libro-Deep-Learning-introduccion-practica-con-Keras-1a-parte.txt”\n",
        "files.upload()\n",
        "\n",
        "#path_to_fileDL ='/content/Libro-Deep-Learning-introduccion-practica-con-Keras-1a-parte.txt'\n",
        "\n",
        "path_to_fileDL = tf.keras.utils.get_file('Shakespear.txt', 'https://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "3ghgaz8lasEF",
        "outputId": "1c67d3c6-07ac-44d2-92c9-67cbac6d789e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb0449bf-828e-43cc-85ba-1ed461ce5ddd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb0449bf-828e-43cc-85ba-1ed461ce5ddd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt\n",
            "99993/99993 [==============================] - 0s 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n",
        "print('Longitud del texto:        {} carácteres'.format(len(text)))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n",
        "print (vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pwSZ1JQbJ-e",
        "outputId": "05e4a6fa-ed1a-4293-8aad-8e502966a122"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del texto:        99993 carácteres\n",
            "El texto está compuesto de estos 62 carácteres:\n",
            "['\\n', ' ', '!', \"'\", ',', '-', '.', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "las redes neuronales solo procesan valores numéricos, no letras, por tanto tenemos que traducir los caracteres a representación numérica. Para ello crearemos dos “tablas de traducción”: una de caracteres a números y otra de números a caracteres:"
      ],
      "metadata": {
        "id": "lup98fzHbhMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "for char,_ in zip(char2idx, range(len(vocab))):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw2OzIv5bW2g",
        "outputId": "73f3f0bd-2d22-4e30-a4d3-dcff9e00687b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  \"'\" :   3,\n",
            "  ',' :   4,\n",
            "  '-' :   5,\n",
            "  '.' :   6,\n",
            "  ':' :   7,\n",
            "  ';' :   8,\n",
            "  '?' :   9,\n",
            "  'A' :  10,\n",
            "  'B' :  11,\n",
            "  'C' :  12,\n",
            "  'D' :  13,\n",
            "  'E' :  14,\n",
            "  'F' :  15,\n",
            "  'G' :  16,\n",
            "  'H' :  17,\n",
            "  'I' :  18,\n",
            "  'J' :  19,\n",
            "  'K' :  20,\n",
            "  'L' :  21,\n",
            "  'M' :  22,\n",
            "  'N' :  23,\n",
            "  'O' :  24,\n",
            "  'P' :  25,\n",
            "  'Q' :  26,\n",
            "  'R' :  27,\n",
            "  'S' :  28,\n",
            "  'T' :  29,\n",
            "  'U' :  30,\n",
            "  'V' :  31,\n",
            "  'W' :  32,\n",
            "  'X' :  33,\n",
            "  'Y' :  34,\n",
            "  'Z' :  35,\n",
            "  'a' :  36,\n",
            "  'b' :  37,\n",
            "  'c' :  38,\n",
            "  'd' :  39,\n",
            "  'e' :  40,\n",
            "  'f' :  41,\n",
            "  'g' :  42,\n",
            "  'h' :  43,\n",
            "  'i' :  44,\n",
            "  'j' :  45,\n",
            "  'k' :  46,\n",
            "  'l' :  47,\n",
            "  'm' :  48,\n",
            "  'n' :  49,\n",
            "  'o' :  50,\n",
            "  'p' :  51,\n",
            "  'q' :  52,\n",
            "  'r' :  53,\n",
            "  's' :  54,\n",
            "  't' :  55,\n",
            "  'u' :  56,\n",
            "  'v' :  57,\n",
            "  'w' :  58,\n",
            "  'x' :  59,\n",
            "  'y' :  60,\n",
            "  'z' :  61,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora tenemos una representación de entero (integer) para cada carácter que podemos ver ejecutando."
      ],
      "metadata": {
        "id": "NAbEgI4xcVfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "metadata": {
        "id": "p-OXplHIcZ0G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('texto: {}'.format(repr(text[:50])))\n",
        "print ('{}'.format(repr(text_as_int[:50])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlYmH6ajct_V",
        "outputId": "f6f4932e-b9c8-492c-d50c-977bdbbe48f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texto: \"That, poor contempt, or claim'd thou slept so fait\"\n",
            "array([29, 43, 36, 55,  4,  1, 51, 50, 50, 53,  1, 38, 50, 49, 55, 40, 48,\n",
            "       51, 55,  4,  1, 50, 53,  1, 38, 47, 36, 44, 48,  3, 39,  1, 55, 43,\n",
            "       50, 56,  1, 54, 47, 40, 51, 55,  1, 54, 50,  1, 41, 36, 44, 55])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparación de los datos para ser usados por la RNN**\n",
        "\n",
        "Para entrenar el modelo prepararemos unas secuencias de caracteres como entradas y salida de un tamaño determinado. En nuestro ejemplo hemos definido el tamaño de 100 caracteres con la variable seq_length (que bien puede  modificarse).\n",
        "\n",
        "Empezamos dividiendo el texto que tenemos en secuencias deseq_length+1de caracteres con las cuales luego contruiremos los datos de entrenamiento compuestos por las entradas de seq_lengthcaracteres y las salidas correspondientes que contienen la misma longitud de texto, excepto que se desplaza un carácter a la derecha. Volviendo al ejemplo de “Hola” anterior, y suponiendo un seq_length=3, la secuencia de entrada será “Hol”, y la de salida será “ola”.\n",
        "\n",
        "Usaremos la función tf.data.Dataset.from_tensor_slices, que crea un conjunto de datos con el contenido del tensortext_as_int que contiene el texto, al que podremos aplicar el método batch( ) para dividir este conjunto de datos en secuencias de  seq_length+1  de índice de caracteres:\n",
        "\n"
      ],
      "metadata": {
        "id": "scYISle7dO27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "seq_length = 100\n",
        "\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "xveONMJVdC_g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos comprobar que sequences contiene el texto dividido en paquetes de 101 caracteres como esperamos (por ejemplo mostremos las 10 primeras secuencias):"
      ],
      "metadata": {
        "id": "zDGzLZXgj6Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for item in sequences.take(10):\n",
        "  print(repr(' '.join(idx2char[item.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBBEOTtWhzfU",
        "outputId": "1c186457-083a-4a40-d700-8d829c9f8722"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"T h a t ,   p o o r   c o n t e m p t ,   o r   c l a i m ' d   t h o u   s l e p t   s o   f a i t h f u l , \\n I   m a y   c o n t r i v e   o u r   f a t h e r ;   a n d ,   i n   t h e i r   d e f e\"\n",
            "'a t e d   q u e e n , \\n H e r   f l e s h   b r o k e   m e   a n d   p u t t a n c e   o f   e x p e d i t i o n   h o u s e , \\n A n d   i n   t h a t   s a m e   t h a t   e v e r   I   l a m e n t  '\n",
            "'t h i s   s t o m a c h , \\n A n d   h e ,   n o r   B u t l y   a n d   m y   f u r y ,   k n o w i n g   e v e r y t h i n g \\n G r e w   d a i l y   e v e r ,   h i s   g r e a t   s t r e n g t h   a'\n",
            "\"n d   t h o u g h t \\n T h e   b r i g h t   b u d s   o f   m i n e   o w n . \\n \\n B I O N D E L L O : \\n M a r r y ,   t h a t   i t   m a y   n o t   p r a y   t h e i r   p a t i e n c e . ' \\n \\n K I N\"\n",
            "'G   L E A R : \\n T h e   i n s t a n t   c o m m o n   m a i d ,   a s   w e   m a y   l e s s   b e \\n a   b r a v e   g e n t l e m a n   a n d   j o i n e r :   h e   t h a t   f i n d s   u s   w i t'\n",
            "\"h   w a x \\n A n d   o w e   s o   f u l l   o f   p r e s e n c e   a n d   o u r   f o o d e r   a t   o u r \\n s t a v e s .   I t   i s   r e m o r s e d   t h e   b r i d a l ' s   m a n   h i s   g\"\n",
            "'r a c e \\n f o r   e v e r y   b u s i n e s s   i n   m y   t o n g u e ,   b u t   I   w a s   t h i n k i n g \\n t h a t   h e   c o n t e n d s ,   h e   h a t h   r e s p e c t e d   t h e e . \\n \\n B'\n",
            "\"I R O N : \\n S h e   l e f t   t h e e   o n ,   I ' l l   d i e   t o   b l e s s e d   a n d   m o s t   r e a s o n a b l e \\n N a t u r e   i n   t h i s   h o n o u r ,   a n d   h e r   b o s o m  \"\n",
            "'i s   s a f e ,   s o m e \\n o t h e r s   f r o m   h i s   s p e e d y - b i r t h ,   a   b i l l   a n d   a s \\n F o r e s t e m   w i t h   R i c h a r d   i n   y o u r   h e a r t \\n B e   q u e s'\n",
            "\"t i o n ' d   o n ,   n o r   t h a t   I   w a s   e n o u g h : \\n W h i c h   o f   a   p a r t i e r   f o r t h   t h e   o b s e r s   d ' p u n i s h ' d   t h e   h a t e \\n T o   m y   r e s t r\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De esta secuencia se obtiene el conjunto de datos de training que contenga tanto los datos de entrada (desde la posición 0 a la 99) como los datos de salida (desde la posición 1 a la 100). Para ello se crea una función que realiza esta tarea y se aplica a todas las secuencias usando el método map( )de la siguiente forma:"
      ],
      "metadata": {
        "id": "QiEo2bs9k0y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "V6H5XfyHkxmq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto, dataset contiene un conjunto de parejas de secuencias de texto (con la representación numérica de los caracteres), donde el primer componente de la pareja contiene un paquete con una secuencia de 100 caracteres del texto original y la segunda su correspondiente salida, también de 100 caracteres. Podemos comprobarlo visualizándolo por pantalla (por ejemplo mostrando la primera pareja):"
      ],
      "metadata": {
        "id": "yvUATETomJUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny0moSHIlj4W",
        "outputId": "5097582c-1bff-47bb-df72-1da1eb6740f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  \"That, poor contempt, or claim'd thou slept so faithful,\\nI may contrive our father; and, in their def\"\n",
            "Target data: \"hat, poor contempt, or claim'd thou slept so faithful,\\nI may contrive our father; and, in their defe\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto del código disponemos de los datos de entrenamiento en el tensor dataset en forma de parejas de secuencias de 100 integersde 64 bits que representan un carácter del vocabulario:"
      ],
      "metadata": {
        "id": "AIMz-irKoeGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuZz8-kclskW",
        "outputId": "b2d44c5d-0e15-4028-9953-0cc4c998ead3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En realidad los datos ya están preprocesados en el formato que se requiere para ser usados en el entreno de la red neuronal, pero recordemos que en redes neuronales los datos se agrupan en batches antes de pasarlos al modelo. En nuestro caso hemos decidido un tamaño de batch de 64, que nos facilita la explicación, este es un hiperparámetro importante de ajustar correctamente teniendo en cuenta diferentes factores, como el tamaño de la memoria disponible, por poner un ejemplo. En este código, para crear los batches de parejas de secuencias hemos considerado usar tf.dataque además nos permite barajar las secuencias previamente:"
      ],
      "metadata": {
        "id": "vHCymoYkouOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "print (dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-iFe4_DpEUj",
        "outputId": "842ce2c5-6103-4319-9714-ba54eed3ec7b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recapitulando, ahora en el tensor dataset disponemos de los datos de entrenamiento ya listos para ser usados para entrenar el modelo: batches compuestos de 64 parejas de secuencias de 100 integers de 64 bits que representan el carácter correspondiente en el vocabulario.\n",
        "\n",
        "## Construcción del modelo RNN\n",
        "Para construir el modelo usaremos tf.keras.Sequential que ya conocemos. Usaremos una versión mínima de RNN para facilitar la explicación, que contenga solo una capa LSTM. En concreto definimos una red de solo 3 capas:"
      ],
      "metadata": {
        "id": "Jl52MlmSpuM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "ih2JyPoDp5_J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size,\n",
        "                      output_dim=embedding_dim,\n",
        "                      batch_input_shape=[batch_size, None]))\n",
        "  model.add(LSTM(rnn_units,\n",
        "                 return_sequences=True,\n",
        "                 stateful=True,\n",
        "                 recurrent_initializer='glorot_uniform'))\n",
        "  model.add(Dense(vocab_size))\n",
        "  return model"
      ],
      "metadata": {
        "id": "qaMTXHuDqVhs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "B_CM4f-xqdFM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La primera capa es de tipo Word Embedding que mapea cada carácter de entrada en un vector Embedding. Esta capa tf.keras.layers.Embedding permite especificar varios argumentos que se pueden consultar en todo detalle en el manual de TensorFlow[21].\n",
        "\n",
        "En nuestro caso el primero que especificamos es el tamaño del vocabulario, indicado con el argumento vocab_size, que indica cuantos vectores Embeddingtendrá la capa.  A continuación indicamos las dimensiones de estos vectores Embeddingmediante el argumento embedding_dim, que en nuestro caso hemos decidido que sea 256.  Finalmente se indica el tamaño del batchque usaremos para entrenar, en nuestro caso 64.\n",
        "\n",
        "La segunda capa es de tipo LSTM introducida anteriormente en este capítulo. Esta capa tf.keras.layers.LSTM tiene varios argumentos posibles que se pueden consultar en el manual de TensorFlow[22], aquí solo usaremos algunos y dejamos los valores por defecto del resto. Quizás el más importante es el número de neuronas recurrentes que se indica con el argumento units y que en nuestro caso hemos decidido que sea 1024 neuronas.\n",
        "\n",
        "Con return_sequencese indica que queremos predecir el carácter siguiente a todos los caracteres de entrada, no solo el siguiente al último carácter.\n",
        "\n",
        "El argumento statefulindica, explicado de manera simple, el uso de las capacidades de memoria de la red entre batches. Si este argumento está instanciado a falsese indica que a cada nuevo batchse inicializan las memory cellscomentadas anteriormente, mientras que si está a truese está indicando para cada batchse mantendrán las actualizaciones hechas durante la ejecución del bachanterior.\n",
        "\n",
        "El último argumento que usamos es recurrent_kernel, donde indicamos cómo se deben inicializar los pesos de las matrices internas de la red. En este caso usamos la distribución uniforme glorot_uniform, habitual en estos casos.\n",
        "\n",
        "Finalmente la última capa es de tipo Dense, ya explicada previamente en este libro. Aquí es importante el argumento units que nos dice cuantas neuronas tendrá la capa y que nos marcará la dimensión de la salida. En nuestro caso será igual al tamaño de nuestro vocabulario (vocab_size).\n",
        "\n",
        "Como siempre, es interesante usar el método summary()para visualizar la estructura del modelo:"
      ],
      "metadata": {
        "id": "MnQOcYLorBHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVbhynBpqkud",
        "outputId": "2985e3a8-b879-4d14-a346-9aed873a0025"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           15872     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 62)            63550     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,326,398\n",
            "Trainable params: 5,326,398\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos comprobar que la capa LSTM consta de muchos parámetros (más de 5 millones) como era de esperar. Intentemos analizar un poco más esta red neuronal. Para cada carácter de entrada (transformado a su equivalente numérico), el modelo busca su vector de Embedding correspondiente y luego ejecuta la capa LSTM con este vector Embeddingcomo entrada. A la salida de la LSTM aplica la capa Densepara decidir cual es el siguiente carácter.\n",
        "\n",
        "Inspeccionemos las dimensiones de los tensores para poder comprender más a fondo el modelo. Fijemonos en el primer batchdel conjunto de datos de entrenamiento y observemos su forma:"
      ],
      "metadata": {
        "id": "iC5qNfmbAEaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  print(\"Input:\", input_example_batch.shape, \"# (batch_size, sequence_length)\")\n",
        "  print(\"Target:\", target_example_batch.shape, \"# (batch_size, sequence_length)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E71d94D39mlj",
        "outputId": "8a62164a-0b0c-4502-9348-2d3856b95413"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: (64, 100) # (batch_size, sequence_length)\n",
            "Target: (64, 100) # (batch_size, sequence_length)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos comprobar que la capa LSTM consta de muchos parámetros (más de 5 millones) como era de esperar. Intentemos analizar un poco más esta red neuronal. Para cada carácter de entrada (transformado a su equivalente numérico), el modelo busca su vector de Embedding correspondiente y luego ejecuta la capa LSTM con este vector Embeddingcomo entrada. A la salida de la LSTM aplica la capa Dense para decidir cual es el siguiente carácter.\n",
        "\n",
        "Inspeccionemos las dimensiones de los tensores para poder comprender más a fondo el modelo. Fijemonos en el primer batch del conjunto de datos de entrenamiento y observemos su forma:"
      ],
      "metadata": {
        "id": "mMef0QphDLux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B09pO7qs9qBB",
        "outputId": "c8b200c1-1e2f-4315-b74d-9a9359ab3ffd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  (64, 100, 62) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revisemos ahora la capa densa de esta red neuronal la cual no tiene una función de activación softmax como la capa densa que tienen algunas redes neuronales. De aquí que retorne el vector con un indicador de “evidencia” para cada carácter.\n",
        "\n",
        "El siguiente paso es elegir uno de los caracteres. Sin entrar en detalle, no se eligirá el carácter más “probable” (mediante argmax) puesto que el modelo puede entrar en un bucle. Lo que se hará es obtener una muestra de la distribución de salida. Pruébelo para el primer ejemplo en el batch:"
      ],
      "metadata": {
        "id": "whnIATpGDyKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "Ve6qVlGl9ztJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con tf.random.categoricalse obtiene una muestra de una distribución categórica y con squeezese elimina la dimensiones del tensor de tamaño 1. De esta manera en cada instante de tiempo se obtiene una predicción del índice del siguiente carácter."
      ],
      "metadata": {
        "id": "PirhHxvuEebE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices_characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHzJJyiz97Oo",
        "outputId": "ba177f32-91fe-4cb2-c69d-82e26cb6bb9f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([48, 50, 50, 41, 55,  3, 34,  9, 24, 12, 37,  3, 29, 30, 37, 11, 57,\n",
              "       41,  4, 47, 46, 39, 33,  8, 60, 29, 51, 58, 50, 61, 29, 36, 23, 47,\n",
              "       61, 14, 55, 47, 15,  2, 54, 28, 19, 25, 33, 17,  1, 21, 32, 35, 28,\n",
              "       13, 24, 55, 61, 42, 23,  9, 10, 16, 61, 30, 43, 45,  2, 37, 40,  6,\n",
              "       13, 52, 58, 60, 54, 20, 27, 37, 23, 26,  5, 12, 18,  2, 57, 53,  9,\n",
              "       56, 32, 30, 48, 16,  3, 52, 49, 52, 15, 58, 57, 15, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del modelo RNN\n",
        "En este punto, el problema puede tratarse como un problema de clasificación estándar para el que debemos definir la función de Lossy el optimizador.\n",
        "\n",
        "Para la función de Loss usaremos la función estándar tf.keras.losses.sparse_categorical_crossentropy dado que estamos considerando datos categóricos. Dado que el retorno hemos visto que se trata de unos valores de verisimilitud (no de probabilidades como si hubiéramos ya aplicado softmax) se instanciará el argumentofrom_logits a True.\n",
        "\n",
        "Entrenar el modelo"
      ],
      "metadata": {
        "id": "7IW3bZp5-MaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "GfP0JUxl-CEO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cuanto al optimizador usaremos tf.keras.optimizers.Adam con los argumentos por defecto del optimizador Adam.\n",
        "\n",
        "Con esta función de loss definida y usando el optimizador Adam con sus argumentos por defecto, ya podemos llamar al método compile () de la siguiente manera:"
      ],
      "metadata": {
        "id": "t62WXCXaFEJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "ZW_TicMV-YOd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejemplo aprovecharemos para usar los Checkpoints[23], una técnica de tolerancia de fallos para procesos cuyo tiempo de ejecución es muy largo. La idea es guardar una instantánea del estado del sistema periódicamente para recuperar desde ese punto la ejecución en caso de fallo del sistema.  En nuestro caso, cuando entrenamos modelos Deep Learning, el Checkpoint lo forman básicamente los pesos del modelo. Estos Checkpoint se pueden usar también para hacer predicciones tal cual como haremos en este ejemplo.\n",
        "\n",
        "La librería de Keras proporciona Checkpoints a través de la API Callbacks.   Concretamente usaremos tf.keras.callbacks.ModelCheckpoint[24]para especificar cómo salvar los Checkpointsa cada epoch durante el entrenamiento, a través de un argumento en el método fit() del modelo.\n",
        "\n",
        "En el código debemos especificar el directorio en el que se guardarán los Checkpoints que salvaremos y el nombre del fichero (que le añadiremos el número de epoch para nuestra comodidad):\n",
        "\n",
        "Configurar Checkpoints"
      ],
      "metadata": {
        "id": "87kFGvU1-kRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # directorio\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# nombre fichero\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "GrCtjs43-dvr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=50\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm7Vjquk-tkL",
        "outputId": "68f7aff5-0624-455f-e2a6-a6db5f5731d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 80s 5s/step - loss: 3.4572\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 3.2118\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 73s 5s/step - loss: 3.0460\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 72s 5s/step - loss: 2.6836\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 75s 5s/step - loss: 2.4725\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 72s 5s/step - loss: 2.3676\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 73s 5s/step - loss: 2.2942\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 72s 5s/step - loss: 2.2267\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 72s 5s/step - loss: 2.1650\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 73s 5s/step - loss: 2.1092\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 73s 5s/step - loss: 2.0544\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 72s 5s/step - loss: 2.0046\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 71s 5s/step - loss: 1.9560\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 72s 5s/step - loss: 1.9078\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 73s 5s/step - loss: 1.8627\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 77s 5s/step - loss: 1.8183\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 77s 5s/step - loss: 1.7748\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 77s 5s/step - loss: 1.7354\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 77s 5s/step - loss: 1.6944\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 77s 5s/step - loss: 1.6573\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 78s 5s/step - loss: 1.6081\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 75s 5s/step - loss: 1.5641\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 77s 5s/step - loss: 1.5254\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 76s 5s/step - loss: 1.4832\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 76s 5s/step - loss: 1.4390\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 77s 5s/step - loss: 1.3916\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 75s 5s/step - loss: 1.3405\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 76s 5s/step - loss: 1.2908\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 77s 5s/step - loss: 1.2313\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 76s 5s/step - loss: 1.1794\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 75s 5s/step - loss: 1.1181\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 1.0549\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.9941\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.9339\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.8622\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 76s 5s/step - loss: 0.7987\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.7369\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.6801\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.6233\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.5710\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 73s 5s/step - loss: 0.5290\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.4873\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.4524\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.4188\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.3926\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 76s 5s/step - loss: 0.3686\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.3470\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.3295\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.3152\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 75s 5s/step - loss: 0.3063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generación de texto\n",
        "\n",
        "Generación de texto usando el modelo RNN\n",
        "Ahora que tenemos ya entrenado el modelo pasemos a usarlo para generar texto. Para mantener este paso de predicción simple, vamos a usar un tamaño de batch de 1. Debido a la forma en que se pasa el estado de la RNN de un instante de tiempo al siguiente, el modelo solo acepta un tamaño de batch fijo una vez construido. Por ello, para poder ejecutar el modelo con un tamaño de batch diferente, necesitamos reconstruir manualmente el modelo con el método build( )del modelo y restaurar sus pesos desde el Checkpoints(cogemos el ultimo con tf.train.latest_checkpoint ()):"
      ],
      "metadata": {
        "id": "GU1B3Rpx_GzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "metadata": {
        "id": "XStb69Iq_BeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "ndY_oT0u_VS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que tenemos el modelo entrenado y preparado para usar, generaremos texto a partir de una palabra de partida con el siguiente código:"
      ],
      "metadata": {
        "id": "JT1l3T8wGJLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 500\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "\n",
        "  temperature = 0.5\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "9uF1afJU_XSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código empieza con inicializaciones como: definir el número de caracteres a predecir con la variable num_generate,convertir la palabra inicial (start_string) a su correspondiente representación numérica y preparan lo tensores necesarios:\n",
        "\n",
        "Usando la misma idea del código original char-rnn[25]de Andrey Karpathy, se usa una variable temperature para decidir cómo de conservador en sus predicciones queremos que se comporte nuestro modelo. En nuestro ejemplo la hemos inicializado a 0.5:\n",
        "\n",
        "Con “temperaturas altas” (hasta 1) se permitirá más creatividad al modelo para generar texto pero a costa de más errores (por ejemplo, errores ortográficos, etc.). Mientras que con “temperaturas bajas” habrá menos errores pero el modelo mostrará poca creatividad. Propongo que el lector pruebe con diferentes valores y vea su efecto. Incluso le propongo que use el datasetShakespeare.txt[26](de tamaño mucho mayor que el presentado en este libro) que Andrey Karpathy usa en su ejemplo original.\n",
        "\n",
        "A partir de este momento empieza el bucle para generar los caracteres que le hemos indicado (que usa el carácter de entrada la primera vez) y luego sus própias predicciones como entrada a cada iteración al modelo RNN:\n",
        "\n",
        "Recordemos que estamos en un batchde 1 pero el modelo retorna el tensor del batchcon las dimensiones que lo habíamos entrenado y por tanto debemos reducir la dimensión batch:\n",
        "\n",
        "\n",
        "\n",
        "Luego, se usa una distribución categórica para calcular el índice del carácter predicho:\n",
        "\n",
        "\n",
        "\n",
        "Este carácter acabado de predecir se usa como nuestra próxima entrada al modelo, retroalimentando el modelo para que ahora tenga más contexto (en lugar de una sola letra). Después de predecir la siguiente letra, se retroalimenta nuevamente, y así sucesivamente de manera que es cómo aprende a medida que se obtiene más contexto de los carácteres predichos previamente:\n",
        "\n",
        "\n",
        "\n",
        "Ahora que se ha descrito cómo se ha programado la función generate_txtprobemos cómo se comporta el modelo.\n",
        "\n",
        "Empecemos con una palabra que no conoce el corpus, por ejemplo “Alcohol”, que nada tiene que ver con Deep Learning:\n",
        "\n",
        "\n",
        "\n",
        "Como vemos el modelo no es capaz de generar ningún texto que tenga ningún parecido a un posible texto relacionado con el tema.\n",
        "\n",
        "Probemos ahora con una palabra como “modelo” o “activación” a ver que pasa:"
      ],
      "metadata": {
        "id": "QkySqnzjGjRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"a\"))"
      ],
      "metadata": {
        "id": "VMfkCpJj_im_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En resumen, el modelo presentado parece que ha aprendido a generar texto de manera interesante, teniendo en cuenta el reducido dataset inicial con el que se ha entrenado. Como ya hemos avanzado, proponemos que el lector pruebe con otros conjuntos de datos de tipo texto. Por ejemplo en el artículo “The Unreasonable Effectiveness of Recurrent Neural Network” del blog de Andrey Karpathy[27]el lector puede encontrar varios ejemplos de datos de tipo texto que el lector puede usar directamente simplemente cambiando la URL del fichero de texto de entrada al código propuesto en este capítulo.\n",
        "\n",
        "Hasta aquí un ejemplo muy simple pero que espero que haya sido útil al lector para comprender la idea que hay detrás de las redes neuronales recurrentes. Un tipo de arquitectura que solo hace pocos años que han iniciado su andadura con resultados impresionante en un amplio abanico de tareas como machine translation[28](2015), language modeling[29](2015) o speech recognition[30](2013) por poner algunos ejemplos.\n",
        "\n",
        "Es sin duda una de las áreas de investigación más activas en Deep Learning en estos momentos, en la que incluso nuestro grupo de investigación está realizando aportaciones[31].  Pero también es un área que genera mucho debate, al poderse crear sistemas que escriben prosa de manera convincente como el presentado recientemente por OpenAI[32]. Un modelo entrenado con miles de millones de palabras para poder crear artículos “creibles”, que muestra cómo estos algoritmos podrían usarse para engañar a las personas a gran escala, automatizando por ejemplo la generación de noticias falsas en redes sociales."
      ],
      "metadata": {
        "id": "sYQnarKwHdq3"
      }
    }
  ]
}